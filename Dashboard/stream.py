import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from collections import Counter
from pyvis.network import Network
import altair as alt
import os
from kiwipiepy import Kiwi
from textblob import TextBlob
from jinja2 import Template
from summarizer import Summarizer
import streamlit.components.v1 as components

@st.cache_data
def create_wordcloud(text):
    # Use font_path to correctly display Korean text
    wordcloud = WordCloud(width=600, height=600, background_color='white', font_path='malgun.ttf').generate(text)
    fig, ax = plt.subplots()
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    return fig

def visualize_word_network(words):
    net = Network(notebook=False, height='600px', width='100%', bgcolor='#ffffff', font_color='black', layout=True)
    word_counts = Counter(words)
    for word, count in word_counts.items():
        net.add_node(word, label=word, size=count*10, color='lightblue', physics=False)
    for i in range(len(words)-1):
        net.add_edge(words[i], words[i+1], color='gray', physics=False)
    
    # Ensure the output directory exists
    output_dir = "output"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    output_path = os.path.join(output_dir, 'word_network.html')
    net.write_html(output_path)
    with open(output_path, 'r', encoding='utf-8') as HtmlFile:
        return HtmlFile.read()

@st.cache_data
def extractive_summarize_korean_text(text, compression_ratio=0.5):
    # BERT ê¸°ë°˜ ì¶”ì¶œ ìš”ì•½ ëª¨ë¸ ìƒì„±
    model = Summarizer()
    summary = model(text, ratio=compression_ratio)
    return summary

# Load or create dataframe (example)
data = {'date': ['2024-10-18', '2024-10-18', '2024-10-17', '2024-10-18', '2024-10-18'],
        'category': ['ê²½ì œ', 'ì •ì¹˜', 'ì‚¬íšŒ', 'ìƒí™œ/ë¬¸í™”', 'IT/ê³¼í•™'],
        'content': ["ê²½ì œ ìƒí™©ì´ ë§¤ìš° ì–´ë µìŠµë‹ˆë‹¤", "ì •ì¹˜ì  ë…¼ë€ì´ ê³„ì†ë˜ê³  ìˆìŠµë‹ˆë‹¤", "ì‚¬íšŒì  ë¬¸ì œì™€ í™˜ê²½ ë¬¸ì œ", "ë¬¸í™” í–‰ì‚¬ì™€ ê´€ë ¨ëœ ìƒˆë¡œìš´ ì†Œì‹", "ê¸°ìˆ  ë°œì „ê³¼ í˜ì‹ ì ì¸ ë‰´ìŠ¤"],
        'title': ["ê²½ì œ ìœ„ê¸°", "ì •ì¹˜ ë…¼ë€", "ì‚¬íšŒ ë¬¸ì œ", "ë¬¸í™” ì†Œì‹", "ê¸°ìˆ  í˜ì‹ "]}
df = pd.DataFrame(data)

# Sentiment analysis function
def analyze_sentiment(text):
    analysis = TextBlob(text)
    if analysis.sentiment.polarity > 0:
        return 'ê¸ì •'
    elif analysis.sentiment.polarity == 0:
        return 'ì¤‘ë¦½'
    else:
        return 'ë¶€ì •'

# Main function
def main():
    st.set_page_config(layout='wide', page_title='ë°ì¼ë¦¬ ë‰´ìŠ¤ ë¦¬í¬íŠ¸ ëŒ€ì‹œë³´ë“œ', page_icon='ğŸ“Š')
    st.title('ë°ì¼ë¦¬ ë‰´ìŠ¤ ë¦¬í¬íŠ¸ ëŒ€ì‹œë³´ë“œ')

    # ë‚ ì§œ ì„ íƒ
    selected_date = st.date_input('ë‚ ì§œ ì„ íƒ', pd.Timestamp('today'))

    # íƒ­ì„ ì´ìš©í•œ ë©”ì¸ ë° ì¹´í…Œê³ ë¦¬ ì„ íƒ
    tab_labels = ['ë©”ì¸', 'ì •ì¹˜', 'ê²½ì œ', 'ì‚¬íšŒ', 'ìƒí™œ/ë¬¸í™”', 'IT/ê³¼í•™']
    tabs = st.tabs(tab_labels)

    # ë©”ì¸ íƒ­
    with tabs[0]:
        st.header('ì „ì²´ ë‰´ìŠ¤ ìš”ì•½ ì •ë³´')
        col1, col2, col3 = st.columns([1, 1, 1], gap="large")
        # ì£¼ìš” ë‰´ìŠ¤
        with col1:
            st.subheader('ì£¼ìš” ë‰´ìŠ¤')
            for i, row in df.iterrows():
                if row['date'] == str(selected_date):
                    st.markdown(f"{i+1}. [{row['title']}]({row['content']}) / {row['category']} ë‰´ìŠ¤")
        # ë¶„ì•¼ë³„ ê¸ˆì¼ ë‰´ìŠ¤ ê°œìˆ˜ ì •ë¦¬
        with col2:
            st.subheader('ë¶„ì•¼ë³„ ë‰´ìŠ¤ ê°œìˆ˜')
            filtered_df = df[df['date'] == str(selected_date)].copy()
            news_count_by_category = filtered_df['category'].value_counts()
            news_count_df = pd.DataFrame({'Category': news_count_by_category.index, 'Count': news_count_by_category.values})
            category_chart = alt.Chart(news_count_df).mark_bar(color='steelblue').encode(
                x=alt.X('Category', sort='-y', axis=alt.Axis(labelAngle=-45)),
                y='Count'
            )
            st.altair_chart(category_chart, use_container_width=True)
        # ë¶„ì•¼ë³„ ì„±í–¥ ë¹„ìœ¨ ì‹œê°í™”
        with col3:
            st.subheader('ë¶„ì•¼ë³„ ì„±í–¥ ë¹„ìœ¨')
            filtered_df['sentiment'] = filtered_df['content'].apply(analyze_sentiment)
            sentiment_by_category = filtered_df.groupby('category')['sentiment'].value_counts(normalize=True).unstack().fillna(0)
            sentiment_by_category = sentiment_by_category.reset_index().melt(id_vars='category', var_name='Sentiment', value_name='Ratio')
            sentiment_chart = alt.Chart(sentiment_by_category).mark_bar().encode(
                x=alt.X('category:N', title='Category'),
                y=alt.Y('Ratio:Q', title='Sentiment Ratio', axis=alt.Axis(format='%')), 
                color=alt.Color('Sentiment:N', scale=alt.Scale(scheme='category10')),
                column='Sentiment:N'
            )
            st.altair_chart(sentiment_chart, use_container_width=True)

    # ì¹´í…Œê³ ë¦¬ë³„ íƒ­
    for idx, selected_category in enumerate(tab_labels[1:]):
        with tabs[idx + 1]:
            # ì„ íƒí•œ ë‚ ì§œ ë° ì¹´í…Œê³ ë¦¬ í•„í„°ë§
            filtered_data = df[(df['category'] == selected_category) & (df['date'] == str(selected_date))]
            if filtered_data.empty:
                st.warning('í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')
                continue

            # ë‰´ìŠ¤ ìš”ì•½ ìƒì„±
            all_text = ' '.join(filtered_data['content'])
            summary = extractive_summarize_korean_text(all_text)
            st.header(f"{selected_category} ë‰´ìŠ¤ ë¦¬í¬íŠ¸")
            st.subheader('ë‰´ìŠ¤ ìš”ì•½')
            st.write(summary)

            # ì»¨í…Œì´ë„ˆ ì‚¬ìš©í•˜ì—¬ ì‹œê°í™”
            with st.container():
                st.markdown("---")
                col1, col2, col3 = st.columns([1, 1, 2], gap="large")
                # ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„±
                with col1:
                    st.subheader('ì›Œë“œ í´ë¼ìš°ë“œ')
                    wordcloud_fig = create_wordcloud(all_text)
                    st.pyplot(wordcloud_fig)
                # ì›Œë“œ ì¹´ìš´íŠ¸ ì‹œê°í™”
                with col2:
                    st.subheader('ê°€ì¥ ë§ì´ ë°œìƒí•œ ë‹¨ì–´')
                    kiwi = Kiwi()
                    tokens = [word.form for word in kiwi.tokenize(all_text) if word.tag.startswith('NN')]
                    word_count = Counter(tokens)
                    word_count_df = pd.DataFrame(word_count.items(), columns=['Word', 'Count']).sort_values(by='Count', ascending=False)
                    bar_chart = alt.Chart(word_count_df).mark_bar(color='lightgreen').encode(
                        x=alt.X('Word', sort='-y', axis=alt.Axis(labelAngle=-45)),
                        y='Count'
                    )
                    st.altair_chart(bar_chart, use_container_width=True)
                # ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”
                with col3:
                    st.subheader('ì›Œë“œ ë„¤íŠ¸ì›Œí¬')
                    if len(tokens) > 1:
                        word_network_html = visualize_word_network(tokens)
                        components.html(word_network_html, height=750)
                    else:
                        st.warning('ì›Œë“œ ë„¤íŠ¸ì›Œí¬ë¥¼ ìƒì„±í•˜ê¸°ì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')

            # ì£¼ìš” í‚¤ì›Œë“œ ì‹œê°í™”
            st.markdown("---")
            st.subheader('ì£¼ìš” í‚¤ì›Œë“œ')
            keywords = word_count_df.head(5)['Word'].tolist()
            st.write(f"ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(keywords)}")

            # ê¸ì •, ë¶€ì • í‰ê°€ ì‹œê°í™”
            st.subheader('ê¸ì •, ë¶€ì • í‰ê°€')
            sentiments = filtered_data['content'].apply(analyze_sentiment)
            sentiment_counts = sentiments.value_counts().to_dict()
            sentiment_df = pd.DataFrame(list(sentiment_counts.items()), columns=['Sentiment', 'Count'])
            pie_chart = alt.Chart(sentiment_df).mark_arc(innerRadius=50).encode(
                theta=alt.Theta('Count', stack=True),
                color=alt.Color('Sentiment', scale=alt.Scale(scheme='category10'))
            )
            st.altair_chart(pie_chart, use_container_width=True)

if __name__ == "__main__":
    main()
